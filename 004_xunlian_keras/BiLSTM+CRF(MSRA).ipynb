{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:35:40.906925Z",
     "start_time": "2019-05-18T06:35:27.682715Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:35:40.962874Z",
     "start_time": "2019-05-18T06:35:40.935022Z"
    }
   },
   "outputs": [],
   "source": [
    "def _parse_data(fh): # 将原始数据按句划分\n",
    "\n",
    "\n",
    "    split_text = '\\n'\n",
    "\n",
    "    string = fh.read().decode('utf-8')\n",
    "    data = [[row.split() for row in sample.split(split_text)] for\n",
    "            sample in\n",
    "            string.strip().split(split_text + split_text)]\n",
    "    fh.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:35:51.557529Z",
     "start_time": "2019-05-18T06:35:40.975774Z"
    }
   },
   "outputs": [],
   "source": [
    "train = _parse_data(open('./train_data.data', 'rb'))\n",
    "test = _parse_data(open('./test_data.data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:36:00.718359Z",
     "start_time": "2019-05-18T06:35:56.583341Z"
    }
   },
   "outputs": [],
   "source": [
    "#word_counts：每个字及其出现的次数\n",
    "word_counts = Counter(row[0].lower() for sample in train for row in sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:36:07.700395Z",
     "start_time": "2019-05-18T06:36:07.669149Z"
    }
   },
   "outputs": [],
   "source": [
    "#vocab: 词汇表(疑问：为什么是出现两次以上？)\n",
    "vocab = [w for w, f in iter(word_counts.items()) if f >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:36:14.631919Z",
     "start_time": "2019-05-18T06:36:14.616299Z"
    }
   },
   "outputs": [],
   "source": [
    "#chunk_tags：标签\n",
    "chunk_tags = ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', \"B-ORG\", \"I-ORG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:36:19.896309Z",
     "start_time": "2019-05-18T06:36:19.880686Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存词汇表和标签\n",
    "with open('./config.pkl', 'wb') as outp:\n",
    "    pickle.dump((vocab, chunk_tags), outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:36:41.668941Z",
     "start_time": "2019-05-18T06:36:41.652963Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "def _process_data(data, vocab, chunk_tags, maxlen=None, onehot=False):\n",
    "    if maxlen is None: # 如果最大句长没有定义，则找出最大句长\n",
    "        maxlen = max(len(s) for s in data)\n",
    "    word2idx = dict((w, i) for i, w in enumerate(vocab))# 为词汇创建索引\n",
    "    x = [[word2idx.get(w[0].lower(), 1) for w in s] for s in data]  # 得到每句话的词汇索引，默认值为1\n",
    "    y_chunk = [[chunk_tags.index(w[1]) for w in s] for s in data] # 得到每句话的标签索引\n",
    "\n",
    "    x = pad_sequences(x, maxlen)  # left padding 序列预处理，不足maxlen的，在前面补0\n",
    "\n",
    "    y_chunk = pad_sequences(y_chunk, maxlen, value=-1) # 序列预处理，不足maxlen的，在前面补-1\n",
    "\n",
    "    if onehot:\n",
    "        y_chunk = numpy.eye(len(chunk_tags), dtype='float32')[y_chunk] # one-hot表示\n",
    "    else:\n",
    "        y_chunk = numpy.expand_dims(y_chunk, 2)\n",
    "    return x, y_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:37:03.471339Z",
     "start_time": "2019-05-18T06:36:52.755259Z"
    }
   },
   "outputs": [],
   "source": [
    "train = _process_data(train, vocab, chunk_tags)\n",
    "test = _process_data(test, vocab, chunk_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:37:33.508540Z",
     "start_time": "2019-05-18T06:37:33.500545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50658, 100), (50658, 100, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape , train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:37:34.413816Z",
     "start_time": "2019-05-18T06:37:34.405830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4631, 100), (4631, 100, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape , test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:37:55.804780Z",
     "start_time": "2019-05-18T06:37:55.732876Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM\n",
    "from keras_contrib.layers import CRF\n",
    "import process_data\n",
    "import pickle\n",
    "\n",
    "EMBED_DIM = 200\n",
    "BiRNN_UNITS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T06:38:01.931990Z",
     "start_time": "2019-05-18T06:37:56.547754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         851600    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 200)         240800    \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, None, 7)           1470      \n",
      "=================================================================\n",
      "Total params: 1,093,870\n",
      "Trainable params: 1,093,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "D:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab), EMBED_DIM, mask_zero=True))  # Random embedding\n",
    "model.add(Bidirectional(LSTM(BiRNN_UNITS // 2, return_sequences=True)))\n",
    "crf = CRF(len(chunk_tags), sparse_target=True)\n",
    "model.add(crf)\n",
    "model.summary()\n",
    "model.compile('adam', loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T09:31:38.942261Z",
     "start_time": "2019-05-18T06:38:05.177622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50658 samples, validate on 4631 samples\n",
      "Epoch 1/10\n",
      "50658/50658 [==============================] - 1615s 32ms/step - loss: 4.0570 - crf_viterbi_accuracy: 0.9535 - val_loss: 7.8862 - val_crf_viterbi_accuracy: 0.9671\n",
      "Epoch 2/10\n",
      "50658/50658 [==============================] - 1460s 29ms/step - loss: 3.9710 - crf_viterbi_accuracy: 0.9782 - val_loss: 7.8657 - val_crf_viterbi_accuracy: 0.9722\n",
      "Epoch 3/10\n",
      "50658/50658 [==============================] - 1216s 24ms/step - loss: 3.9576 - crf_viterbi_accuracy: 0.9843 - val_loss: 7.8614 - val_crf_viterbi_accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "50658/50658 [==============================] - 790s 16ms/step - loss: 3.9513 - crf_viterbi_accuracy: 0.9878 - val_loss: 7.8576 - val_crf_viterbi_accuracy: 0.9791\n",
      "Epoch 5/10\n",
      "50658/50658 [==============================] - 751s 15ms/step - loss: 3.9468 - crf_viterbi_accuracy: 0.9913 - val_loss: 7.8587 - val_crf_viterbi_accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "50658/50658 [==============================] - 741s 15ms/step - loss: 3.9441 - crf_viterbi_accuracy: 0.9936 - val_loss: 7.8640 - val_crf_viterbi_accuracy: 0.9793\n",
      "Epoch 7/10\n",
      "50658/50658 [==============================] - 1239s 24ms/step - loss: 3.9421 - crf_viterbi_accuracy: 0.9954 - val_loss: 7.8678 - val_crf_viterbi_accuracy: 0.9792\n",
      "Epoch 8/10\n",
      "50658/50658 [==============================] - 1272s 25ms/step - loss: 3.9408 - crf_viterbi_accuracy: 0.9965 - val_loss: 7.8729 - val_crf_viterbi_accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "50658/50658 [==============================] - 659s 13ms/step - loss: 3.9399 - crf_viterbi_accuracy: 0.9974 - val_loss: 7.8759 - val_crf_viterbi_accuracy: 0.9801\n",
      "Epoch 10/10\n",
      "50658/50658 [==============================] - 658s 13ms/step - loss: 3.9394 - crf_viterbi_accuracy: 0.9979 - val_loss: 7.8777 - val_crf_viterbi_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "# train model\n",
    "model.fit(train_x, train_y,batch_size=16,epochs=EPOCHS, validation_data=[test_x, test_y])\n",
    "model.save('./crf_MSRA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T10:57:53.010452Z",
     "start_time": "2019-05-18T10:57:33.450792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 7.877739022653835\n",
      "Test accuracy: 0.980469312685351\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T11:15:29.744739Z",
     "start_time": "2019-05-18T11:15:29.736748Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen=100 # 最大句长\n",
    "predict_text = '''中华人民共和国国务院总理周恩来在外交部长陈毅的陪同下，\n",
    "连续访问了埃塞俄比亚等非洲10国以及阿尔巴尼亚'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T11:17:34.723811Z",
     "start_time": "2019-05-18T11:17:31.083444Z"
    }
   },
   "outputs": [],
   "source": [
    "word2idx = dict((w, i) for i, w in enumerate(vocab))\n",
    "x = [word2idx.get(w[0].lower(), 1) for w in predict_text]\n",
    "length = len(x)\n",
    "x = pad_sequences([x], maxlen)\n",
    "model.load_weights('./crf1.h5')\n",
    "raw = model.predict(x)[0][-length:]\n",
    "result = [np.argmax(row) for row in raw]\n",
    "result_tags = [chunk_tags[i] for i in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T12:26:21.879039Z",
     "start_time": "2019-05-18T12:26:21.867056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " person: 周恩来 陈毅 \n",
      " location: 埃塞俄比亚 非洲 阿尔巴尼亚 \n",
      " organzation: 中华人民共和国国务院 外交部 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "per, loc, org = '', '', ''\n",
    "\n",
    "for s, t in zip(predict_text, result_tags):\n",
    "    if t in ('B-PER', 'I-PER'):\n",
    "        per += ' ' + s if (t == 'B-PER') else s\n",
    "    if t in ('B-ORG', 'I-ORG'):\n",
    "        org += ' ' + s if (t == 'B-ORG') else s\n",
    "    if t in ('B-LOC', 'I-LOC'):\n",
    "        loc += ' ' + s if (t == 'B-LOC') else s\n",
    "\n",
    "print(' person:' + per, '\\n',\n",
    "      'location:' + loc, '\\n', \n",
    "      'organzation:' + org, '\\n',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
